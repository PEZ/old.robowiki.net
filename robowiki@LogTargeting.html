<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML//EN">
<HTML><HEAD><TITLE>LogTargeting - Robo Wiki -= Collecting Robocode Knowledge =-</TITLE>
<META NAME='KEYWORDS' CONTENT='Log, Targeting'/>
<LINK REL="stylesheet" HREF="/robodocs/wiki.css">
</HEAD><BODY BGCOLOR="white">
<div class=wikiheader><h1><a href="robowiki@Robo_Home"><img src="/images/RoboWiki.png" alt="[Home]" border=0 align="right"></a><a href="robowiki@back=LogTargeting">LogTargeting</a></h1><a href="robowiki@Robo_Home" class=wikipagelink>Robo Home</a> | <a href="robowiki@Changes" class=wikipagelink>Changes</a> | <a href="robowiki@action=editprefs">Preferences</a> | <a href='?action=index'>AllPages</a><br>
<hr class=wikilineheader></div><div class=wikitext>Targeting systems that utilize a detailed log of enemy data to predict where the target will be.  The classic version of this is <a href="robowiki@PatternMatching" class=wikipagelink>PatternMatching</a>. Can work very well against simple bots and is currently a great way to hit <a href="robowiki@WaveSurfers" class=wikipagelink>WaveSurfers</a>, but suffers from a long learning time and high processor loads, and the need for <a href="robowiki@DealingWithSkippedTurns" class=wikipagelink>DealingWithSkippedTurns</a>.
<p>
<a href="robowiki@PatternMatching" class=wikipagelink>PatternMatching</a> - Checking the targets current actions against things they had done in the past. The main goal is trying to balance precision with the fuzziness factor, and keeping it as fast as possible. Subsets of this are <a href="robowiki@MogBot" class=wikipagelink>MogBot</a> style, <a href="robowiki@SymbolicPatternMatching" class=wikipagelink>SymbolicPatternMatching</a>, and whatever you want to call <a href="robowiki@TronsGun" class=wikipagelink>TronsGun</a>.
<p>
<a href="robowiki@NeuralTargeting" class=wikipagelink>NeuralTargeting</a> - Using neural nets to predict enemy behavior. Rather obscure and very high level, but could have definite potential.
<p>
CommandReconstructionTargeting<a href="robowiki@action=edit&id=CommandReconstructionTargeting" class=wikipageedit>?</a> - A very obscure targeting method.  Analyzes enemy behavior to calculate the commands that would give the result.  Then once given the command list, attempts to reconstruct the movement code and use that to predict movement. The <a href="robowiki@HolyGrail" class=wikipagelink>HolyGrail</a> of Targeting if implemented. 
<p>
SOOLTargeting - The log is self ordering. <a href="robowiki@Locke" class=wikipagelink>Locke</a> uses it successfully. A description of the algorithm can be found on <a href="robowiki@Locke" class=wikipagelink>Locke</a>'s page.
<p>
<hr noshade class=wikiline size=1>
Why are neural networks counted as log targeting? You use certain patterns (e.g. your enemy's velocity, heading, position) to train your neural network, but I doubt that you can find back what your enemy's bot was doing X ticks ago, like in a log. --<a href="robowiki@Dummy" class=wikipagelink>Dummy</a>
<UL >
<li> anyone??? I really don't think that NeuralNetworks<a href="robowiki@action=edit&id=NeuralNetworks" class=wikipageedit>?</a> fit the defenition of <a href="robowiki@LogTargeting" class=wikipagelink>LogTargeting</a> given above... -- <a href="robowiki@Dummy" class=wikipagelink>Dummy</a>
</UL>
<p>
<UL >
<li> I can't say because I don't know very much about neural nets, but if you know a better category to put it in then I say go for it. --<a href="robowiki@Wcsv" class=wikipagelink>wcsv</a>
</UL>
<p>
<UL >
<li>If you look at bullet/item #3 on <a href="robowiki@Albert" class=wikipagelink>Albert</a>'s <a href="robowiki@TrainingTheNN" class=wikipagelink>TrainingTheNN</a> page, he mentions that training the network with ordered observations didn't work well for him. Instead, he logs his scans and trains the network with a random scan from history. Hence, the <a href="robowiki@LogTargeting" class=wikipagelink>LogTargeting</a> categorization. It's not the only way to train a network. <a href="robowiki@Chomsky" class=wikipagelink>Chomsky</a> trains with observations as they come so he's not really using <a href="robowiki@LogTargeting" class=wikipagelink>LogTargeting</a>. --<a href="robowiki@Corbos" class=wikipagelink>Corbos</a>
</UL>
<p>
<UL >
<li>I see. That means keeping a log isn't a requirement then. What do you guys think of 'Heuristics' as a category? Stuff like FuzzyLogic<a href="robowiki@action=edit&id=FuzzyLogic" class=wikipageedit>?</a> and GeneticAlgorithms<a href="robowiki@action=edit&id=GeneticAlgorithms" class=wikipageedit>?</a> should fit that category, I think. -- <a href="robowiki@Dummy" class=wikipagelink>Dummy</a>
</UL>
<p>
<UL >
<li> Seems like a good idea to me. I think a lot of the stuff on the second level pages could use some review and/or reorganization. -- <a href="robowiki@Voidious" class=wikipagelink>Voidious</a>
</UL>
</div><hr class=wikilinefooter>
<div class=wikifooter><form method="post" action="robowiki" enctype="application/x-www-form-urlencoded">
<a href="robowiki@Robo_Home" class=wikipagelink>Robo Home</a> | <a href="robowiki@Changes" class=wikipagelink>Changes</a> | <a href="robowiki@action=editprefs">Preferences</a> | <a href='?action=index'>AllPages</a><br>
<a href="robowiki@action=edit&id=LogTargeting" class=wikipageedit>Edit text of this page</a> | <a href="robowiki@action=history&id=LogTargeting">View other revisions</a><br>Last edited January 17, 2006 0:02 EST by <a href="robowiki@Voidious" title="ID 5554 from resnet216-234.resnet.buffalo.edu">Voidious</a> <a href="robowiki@action=browse&diff=1&id=LogTargeting">(diff)</a><br>Search: <input type="text" name="search"  size="20" /><input type="hidden" name="dosearch" value="1"  /></form></div>
</body>
</html>